"""
Pydantic models for the PhotoeAI backend application.
Defines the data structures for user input, wizard input, and brief output.
"""

from pydantic import BaseModel, Field
from typing import Optional, Dict, Any


class InitialUserRequest(BaseModel):
    """Model for the initial user request containing a simple text description."""
    user_request: str


class WizardInput(BaseModel):
    """
    Comprehensive model for structured product photography parameters.
    Used to capture all aspects of a photography brief through the wizard interface.
    """
    # Section 1: Main Subject & Story
    product_name: Optional[str] = None
    user_request: Optional[str] = None
    product_description: Optional[str] = None
    key_features: Optional[str] = None
    product_state: Optional[str] = None

    # Section 2: Composition & Framing
    shot_type: Optional[str] = None
    framing: Optional[str] = None
    compositional_rule: Optional[str] = None
    negative_space: Optional[str] = None

    # Section 3: Lighting & Atmosphere
    lighting_style: Optional[str] = None
    key_light_setup: Optional[str] = None
    fill_light_setup: Optional[str] = None
    rim_light_setup: Optional[str] = None
    mood: Optional[str] = None

    # Section 4: Background & Setting
    environment: Optional[str] = None
    dominant_colors: Optional[str] = None
    accent_colors: Optional[str] = None
    props: Optional[str] = None

    # Section 5: Camera & Lens
    camera_type: Optional[str] = None
    lens_type: Optional[str] = None
    aperture_value: Optional[float] = None
    shutter_speed_value: Optional[int] = None
    iso_value: Optional[int] = None
    visual_effect: Optional[str] = None

    # Section 6: Style & Post-Production
    overall_style: Optional[str] = None
    photographer_influences: Optional[str] = None


class BriefOutput(BaseModel):
    """Model for the final enhanced photography brief output."""
    final_prompt: str


# --- NEW MODELS ---

class TextGenerationRequest(BaseModel):
    """
    Request model for text generation using various AI providers.
    Supports the different endpoints shown by the user.
    """
    prompt: str = Field(..., description="The text prompt for generation")
    user_api_key: str = Field(..., description="User-provided API key for the AI service")
    provider: Optional[str] = Field(None, description="Override provider (sumopod, openrouter, openai, gemini)")
    model: Optional[str] = Field(None, description="Specific model to use (e.g., gpt-4o, gemini-2.5-flash)")
    max_tokens: Optional[int] = Field(150, description="Maximum tokens to generate")
    temperature: Optional[float] = Field(0.7, description="Sampling temperature (0.0 to 1.0)")
    
    class Config:
        schema_extra = {
            "example": {
                "prompt": "Generate a detailed photography brief for luxury skincare products",
                "user_api_key": "your-api-key-here",
                "provider": "openrouter",
                "model": "openai/gpt-4o",
                "max_tokens": 200,
                "temperature": 0.8
            }
        }


class TextOutput(BaseModel):
    """Output model for text generation responses."""
    generated_text: str = Field(..., description="The generated text content")
    provider_used: str = Field(..., description="Which provider was used for generation")
    model_used: str = Field(..., description="Which model was used for generation")
    generation_metadata: Dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
    
    class Config:
        schema_extra = {
            "example": {
                "generated_text": "A comprehensive photography brief for luxury skincare...",
                "provider_used": "openrouter", 
                "model_used": "openai/gpt-4o",
                "generation_metadata": {
                    "tokens_used": 156,
                    "response_time": "2.3s",
                    "timestamp": "2024-08-23T10:00:00Z"
                }
            }
        }


class ImageGenerationRequest(BaseModel):
    """Model for the initial image generation request."""
    brief_prompt: str = Field(..., description="The final, enhanced brief prompt generated by the /generate-brief endpoint.")
    user_api_key: str = Field(..., description="User's API key for the image generation service.")
    negative_prompt: Optional[str] = Field(None, description="Optional concepts to exclude from the image.")
    style_preset: Optional[str] = Field("photorealistic", description="Artistic style for the image generation.")
    provider: Optional[str] = Field(None, description="Optional provider override (stability_ai, openai_dalle, openrouter, sumopod, midjourney)")

class ImageEnhancementRequest(BaseModel):
    """Model for iteratively enhancing a previously generated image."""
    original_brief_prompt: str = Field(..., description="The original brief that created the image.")
    generation_id: str = Field(..., description="The unique ID of the image being enhanced.")
    enhancement_instruction: str = Field(..., description="User's instruction for what to change, e.g., 'Make it colder with more condensation.'")
    user_api_key: str = Field(..., description="User's API key for the image generation service.")
    seed: Optional[int] = Field(None, description="The seed of the original image to maintain consistency.")
    provider: Optional[str] = Field(None, description="Optional provider override (stability_ai, openai_dalle, openrouter, sumopod, midjourney)")

class ImageOutput(BaseModel):
    """Model for the response after a successful image generation."""
    image_url: str
    generation_id: str
    seed: int
    revised_prompt: str

# --- END NEW MODELS ---
